{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "327e38b8-ac9d-429c-a34f-98b2a54a998a",
   "metadata": {},
   "source": [
    "# Fine-Tuning a Low-Resource Translation Model: English-Irish\n",
    "\n",
    "Developing high-quality machine translation systems for low-resource languages like Irish presents significant challenges. While large language models have shown impressive translation capabilities, smaller models that are more practical to deploy often struggle to achieve acceptable quality. In this post, we'll explore an approach to fine-tuning a smaller language model for English-Irish translation using techniques like two-stage training with parallel corpora and Direct Preference Optimization. The goal is to create a cost-effective, deployable model that can be integrated into applications like an interactive translation tool.\n",
    "\n",
    "![The GUI using FastHTML for Iirsh English Tutor](./images/irish_eng.png)\n",
    "\n",
    "Previous work on low-resource language model training, such as UCCIX's Irish LLM, relied on filtering data from common web crawls. However, for this project, we instead used the parallel English-Irish corpus of legislation collected by [Gaois](https://www.gaois.ie/en/corpora/parallel/data). This corpus contains high-quality, human-translated paragraph pairs, making it a valuable resource. One draw-back is uses a lot of legal formal language, so to imporve diversity I also included  [Tatoeba]([https://tatoeba.org/en/downloads](https://tatoeba.org/en/downloads)), which is a large database of sentences and translations, the results from the voluntary contributions of thousands of members. \n",
    "\n",
    "With the Gaois Irish legislation data, we had over 900k rows of parallel Irish and English paragraphs. Minor misalignments, specifically non-matching Irish-English sentence pairs, were more prevalent in shorter sentences and were excluded. The final dataset breakdown:\n",
    "\n",
    "- **Included entries:** 628,942 (63.9%)\n",
    "- **Excluded entries:** 354,967 (36.1%)\n",
    "- **Random sub-sample:** 14,000\n",
    "\n",
    "Due to computational cost, a 14k random subsample was used for the initial model development. The most advanced model available at the time, GPT4o, was used to translate the examples to ensure even the rejected (non-preferred) translations were of good quality.\n",
    "\n",
    "## Preference Optimization Approach\n",
    "\n",
    "To fine-tune the translation model, we applied concepts from both [UCCIX's](https://arxiv.org/abs/2405.13010) work and [Huggingface's Contrastive Preference Optimization (CPO)](https://arxiv.org/abs/2401.08417) approach, with some adjustments.\n",
    "\n",
    "Xu et al. 2023 found a two-stage approach worked best on LLama-2, using a large amount of monolingual examples followed by a supervised fine-tuning (SFT) stage on parallel data along with instructing the model to translate. UCCIX used a similar two-stage approach but reversed the order, starting with SFT on parallel data to establish cross-lingual relationships, followed by monolingual data to capture cultural nuances. \n",
    "\n",
    "However, relying solely on human-translated \"gold standard\" examples for SFT can limit performance. Leveraging reference-free evaluation models like COMET-XXL ([Unbabel/wmt23-cometkiwi-da-xxl](https://huggingface.co/Unbabel/wmt23-cometkiwi-da-xxl)) from Unbabel allows scoring translations without a human reference by treating the evaluation as a quality estimation problem. \n",
    "\n",
    "Using COMET-XXL, we scored translations from GPT4o and selected the higher scoring one as the preferred example, with human translations favored in case of ties. This produced a dataset of both accepted and rejected translations suitable for training with Direct Preference Optimization (DPO). DPO relies on labeled preference data rather than just positive examples.\n",
    "\n",
    "UCCIX's work expanded the base Llama-2 tokenizer vocabulary to better handle Irish-specific tokens, such as fadas (accented characters), improving performance and generation speed. However, this adjustment may have contributed to some degradation in English performance, a phenomenon they termed \"catastrophic forgetting.\" Huggingface similarly reported reduced English performance in their experiments. Following their approach, I used the [ReliableAI/UCCIX-Llama2-13B-Instruct](https://huggingface.co/ReliableAI/UCCIX-Llama2-13B-Instruct) model, which was already fine-tuned via supervised fine-tuning (SFT), as the base for the second phase of fine-tuning using preference optimization methods like CPO/DPO.\n",
    "\n",
    "Huggingface employed CPO, which addresses certain [memory and performance](https://arxiv.org/abs/2401.08417) concerns associated with DPO while maintaining the same preference dataset structure. They also provide a dedicated [`CPOTrainer`](https://huggingface.co/docs/trl/main/en/cpo_trainer) for this approach. However, I opted for the DPO algorithm as it is better supported by Axolotl.\n",
    "\n",
    "## Data Formatting scripts\n",
    "\n",
    "See my specific repo for this part [here](https://github.com/c123ian/Irish_Eng_Training). Data downloaded from [Tatoeba]([https://tatoeba.org/en/downloads](https://tatoeba.org/en/downloads)) (community generated pairs) and Gaois (legislation pairs).\n",
    "\n",
    "```json\n",
    "585265,Go raibh míle maith agat!,\n",
    "1564,Thank you very much!\n",
    "```\n",
    "\n",
    "The two datasets are in differing formats, so need two separate notebooks to format them (for example, Gaois is very large after concatenating the `thx` files, so we take a subsample).\n",
    "\n",
    "1. `irish_eng_data_final_1st_ds_Gaois.ipynb\n",
    "2. `irish_eng_data_2nd_ds_Tatoeba.ipynb\n",
    "\n",
    "We then use the GPT4o API to translate in both directions and saved as `translated.jsonl`\n",
    "\n",
    "``` json\n",
    "{\n",
    "\"en\": \"DAIRY PRODUCE (PRICE STABILISATION) ACT, 1933\", \n",
    "\"ga\": \"ACHT TORA DÉIRÍOCHTA (PRAGHAS DO DHÉANAMH SEASMHACH), 1933.\", \n",
    "\"gpt_4_ga\": \"ACHT UM SHOCRÚ PRAGHAS TÁIRGÍ DAIRÍ, 1933\", \n",
    "\"gpt_4_en\": \"DESTRUCTION OF WEEDS (STABILIZATION OF PRICE) ACT, 1933.\"\n",
    "}\n",
    "```\n",
    "\n",
    "After dataset is stored locally, run the `download_cometxxl.py` which downloads the reference comet model free to evaluate translations. The model from provided Huggingface Hub path, in this case `Unbabel/wmt23-cometkiwi-da-xxl`.\n",
    "\n",
    "Once data model is downloaded to a Modal Labs Volume like so:\n",
    "\n",
    "```\n",
    "┏━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┓\n",
    "┃ Filename       ┃ Type ┃ Created/Modified                   ┃ Size     ┃\n",
    "┡━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━┩\n",
    "┡━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━┩\n",
    "│ checkpoints    │ dir  │ 2024-12-30 17:14 GMT Standard Time │ 0 B      │\n",
    "│ README.md      │ file │ 2024-12-30 17:14 GMT Standard Time │ 4.0 KiB  │\n",
    "│ LICENSE        │ file │ 2024-12-30 17:14 GMT Standard Time │ 20.3 KiB │\n",
    "│ .gitattributes │ file │ 2024-12-30 17:14 GMT Standard Time │ 1.5 KiB  │\n",
    "│ .cache         │ dir  │ 2024-12-30 17:14 GMT Standard Time │ 11 B     │\n",
    "└────────────────┴──────┴────────────────────────────────────┴──────────┘\n",
    "```\n",
    "\n",
    "We grade the translations `script_cometxl_scorer.py `which also formats the dataset into what cometxl expects (with `src` and `mt` columns). The `system_score` is there to average multiple reference model scores, but in this case we only used one model). The reference free model then grades the translations between 0-100 with closer to 100 being a 'perfect' translation.\n",
    "\n",
    "```json\n",
    "{\"src\": \"Thank you very much!\", \"mt\": \"Go raibh míle maith agat!\", \n",
    "\"direction\": \"en-ga\", \n",
    "\"cometkiwi_score\": 0.8342427015304565, \n",
    "\"system_score\": 0.8342427015304565}\n",
    "\n",
    "{\"src\": \"Go raibh míle maith agat!\", \n",
    "\"mt\": \"Thank you very much!\", \n",
    "\"direction\": \"ga-en\", \n",
    "\"cometkiwi_score\": 0.8411319851875305, \n",
    "\"system_score\": 0.8411319851875305}\n",
    "```\n",
    "\n",
    "Once graded, we format it a final time to what DPO would expect using `script_preference_ds_formatter.py` and the higher rated translations are placed in `accepted` and the latter in `rejected`. \n",
    "\n",
    "```json\n",
    "{\"prompt\": \"Search Cuardach\", \n",
    "\"chosen\": \"Cuardach\", \n",
    "\"rejected\": \"Cuardach Search\"}\n",
    "\n",
    "{\"prompt\": \"Cuardach Search\", \n",
    "\"chosen\": \"Search Cuardach\", \n",
    "\"rejected\": \"Search\"}\n",
    "```\n",
    "\n",
    "The dataset is ready to finetune a chosen model via Axolotl (hosted on Jarvis Labs).\n",
    "\n",
    "## Model Training\n",
    "\n",
    "With the preference data prepared, the model was fine-tuned using [Axolotl](https://github.com/axolotl-ai-cloud/axolotl), a tool for streamlining training across different model configurations. Axolotl recently added support for DPO. \n",
    "\n",
    "The training `config` was based on the Axolotl [example](https://github.com/axolotl-ai-cloud/axolotl/blob/main/examples/llama-3/instruct-dpo-lora-8b.yml) for Llama-3 models:\n",
    "\n",
    "```yaml\n",
    "rl: dpo  \n",
    "datasets:  \n",
    "- path: c123ian/irish_eng_transl_2k_test_uuix\n",
    "split: train  \n",
    "type: chatml.intel   \n",
    "\n",
    "adapter: qlora  \n",
    "lora_model_dir:  \n",
    "  \n",
    "sequence_len: 4096  \n",
    "sample_packing: false # set false for RFL  \n",
    "```\n",
    "\n",
    "The preference dataset was structured based on the `Intel/orca_dpo_pairs` format expected by Axolotl. Here's an example below, notice subtle difference in the translations:\n",
    "\n",
    "```json\n",
    "{\"system\": \"You are an AI assistant. You will be given a sentence to translate:\", \"question\": \"You need not come to the office on Saturdays.\",  \n",
    "\"chosen\": \"Ní gá duit dul go dtí an oifig gach Satharn.\",  \n",
    "\"rejected\": \"Ní gá duit teacht chuig an oifig ar an Satharn.\"}  \n",
    "{\"system\": \"You are an AI assistant. You will be given a sentence to translate:\", \"question\": \"Ní gá duit dul go dtí an oifig gach Satharn.\",  \n",
    "\"chosen\": \"You need not come to the office on Saturdays.\",  \n",
    "\"rejected\": \"You don't have to go to the office every Saturday.\"} \n",
    "```\n",
    "\n",
    "Once the data and config were ready, the model was trained using:\n",
    "\n",
    "`python3 -m axolotl.cli.train examples/llama-3/instruct-dpo-lora-8b.yml`\n",
    "\n",
    "After training, the LORA adapter was merged with the base model:\n",
    "\n",
    "`python3 -m axolotl.cli.merge_lora your_config.yml --lora_model_dir=\"./completed-model\"`\n",
    "\n",
    "The merged model was then pushed to the Huggingface Hub for deployment.\n",
    "\n",
    "## Deployment\n",
    "\n",
    "To make the model easily accessible, an interactive web application was built using the FastHTML framework. The app provides a chat interface for users to converse with the model and request translations. \n",
    "\n",
    "The core application logic, including model inference, was implemented using Modal, a platform for deploying machine learning applications. Modal's decorators were used to define API endpoints and configure the vLLM for accelerated inference.\n",
    "\n",
    "You can see the full source code for the application [here](https://github.com/c123ian/Irish_Tutor). A live demo of the English-Irish translation assistant is available to try out [here](https://c123ian--irish-chatbot-serve-fasthtml.modal.run). Note that the demo is currently using the UCCIX-Instruct model while final testing of our fine-tuned model is underway.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This project demonstrates an approach for fine-tuning a compact language model for high-quality translation of a low-resource language pair like English-Irish. By combining techniques from prior work, including two-stage training on parallel and monolingual data, expanded vocabulary tokenization, and preference optimization using DPO, we were able to create a deployable model that can be integrated into downstream applications.\n",
    "\n",
    "Some key learnings and takeaways:\n",
    "- High-quality parallel corpora, even if smaller in size, can be more effective than larger but noisier datasets from general web crawls.\n",
    "- Reference-free evaluation using models like COMET-XL enables optimization beyond human-labeled examples.\n",
    "- Expanding the tokenizer vocabulary for the target language can boost performance but may impact source language quality.\n",
    "- Emerging tools like Axolotl are making it easier to experiment with different RFHL fine-tuning approaches like DPO.\n",
    "\n",
    "There are many promising directions to build on this work, such as:\n",
    "- Comparing DPO with other preference learning approaches like CPO.\n",
    "- Investigating techniques to mitigate negative effects on source language performance.\n",
    "- Expanding the application to support more advanced features like contextual translation and conversation history (see my other project which uses a LLM and Conversation History [here](https://github.com/c123ian/Irish_Tutor))\n",
    "\n",
    "Developing practical machine translation systems for under-resourced languages is an important challenge. Hopefully, the approach outlined here can serve as a starting point for others working to bring the benefits of large language models to these languages and communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f88df5-5ffd-4a4b-af8c-37e585fd797c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
